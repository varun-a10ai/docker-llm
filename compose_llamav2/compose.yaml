version: '3'
services:
  llamav2:
    build:
      context: .
      network: host
      dockerfile: Dockerfile
    image: ghcr.io/varun-a10ai/docker-llamav2:main
    command: /bin/bash
    volumes:
      - /mnt/raid/hf_cache:/hf_cache
      - /mnt/s3_catfs:/s3/alphahealth-ml-artifacts
      - $PWD:/app
      - $HOME/.config/:/root/.config/
      - $HOME/.cache/:/root/.cache/
    environment:
      - TRANSFORMERS_CACHE=/hf_cache
      - MAKEFLAGS="-j32"
    network_mode: host
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 8
              capabilities: [gpu]
